{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "import os\n",
    "#import Pillow\n",
    "#from PIL import Image\n",
    "#import opencv\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array, array_to_img\n",
    "from keras.preprocessing.image\n",
    "\n",
    "num_train = 2000              # 訓練データの画像数\n",
    "num_validation = 800          # テストデータの画像数\n",
    "img_h, img_w = 150, 150       # 画像のサイズ\n",
    "channels = 3                  # チャンネル数\n",
    "batch_size = 32               # ミニバッチのサイズ\n",
    "train_data_dir = 'data/train' # 訓練データのフォルダー\n",
    "validation_data_dir = 'data/validation' # テストデータのフォルダー\n",
    "result_dir = 'results'        # VGG16の出力結果を保存するフォルダー\n",
    "\n",
    "# resultsフォルダーが存在しなければ作成\n",
    "if not os.path.exists(result_dir):\n",
    "    os.mkdir(result_dir)\n",
    "\n",
    "    \n",
    "def save_VGG16_outputs():\n",
    "    '''\n",
    "    VGG16にDog vs Catの訓練データ、テストデータを入力し、\n",
    "    出力結果をnpyファイルに保存する\n",
    "    \n",
    "　　'''  \n",
    "    # VGG16モデルと学習済み重みを読み込む\n",
    "    model = VGG16(\n",
    "        include_top=False,            # 全結合層は層（FC）は読み込まない\n",
    "        weights='imagenet',           # ImageNetで学習した重みを利用\n",
    "        input_shape=(img_h, img_w, channels) # 入力データの形状\n",
    "    )\n",
    "    \n",
    "    # サマリを表示\n",
    "    model.summary()\n",
    "\n",
    "    # 訓練データとテストデータを読み込むジェネレーターを生成\n",
    "    datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "    # Dog vs Catの訓練データを生成するするジェネレーター\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,               # 訓練データのフォルダー\n",
    "        target_size=(img_w, img_h),   # 画像をリサイズ\n",
    "        batch_size=batch_size,        # ミニバッチのサイズ\n",
    "        class_mode=None,              # 出力層は存在しないのでclass_modeはNone\n",
    "        shuffle=False)                # データをシャッフルしない\n",
    "    # テストデータの正解ラベルを出力\n",
    "    print('train-label:',train_generator.class_indices) \n",
    "    # 訓練データをVGG16モデルに入力し、その出力をファイルに保存\n",
    "    vgg16_train = model.predict_generator(\n",
    "        train_generator,              # ジェネレーター\n",
    "        steps = len(train_generator), # ジェネレーターのサイズを設定\n",
    "        verbose=1                     # 進捗状況を出力\n",
    "    )\n",
    "    # 訓練データの出力を保存\n",
    "    np.save(os.path.join(result_dir, 'vgg16_train.npy'),\n",
    "            vgg16_train)\n",
    "\n",
    "    # Dog vs Catのテストデータを生成するジェネレーター\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,          # テストデータのフォルダー\n",
    "        target_size=(img_w, img_h),   # 画像をリサイズ\n",
    "        batch_size=batch_size,        # ミニバッチのサイズ\n",
    "        class_mode=None,              # 出力層は存在しないのでclass_modeはNone\n",
    "        shuffle=False)                # データをシャッフルしない\n",
    "    \n",
    "    \n",
    "    # テストデータの正解ラベルを出力\n",
    "    print('test-label:',validation_generator.class_indices)\n",
    "    \n",
    "    \n",
    "    # テストデーターをVGG16モデルに入力する\n",
    "    vgg16_test = model.predict_generator(\n",
    "        validation_generator,              # ジェネレーター\n",
    "        steps = len(validation_generator), # ジェネレーターのサイズを設定\n",
    "        verbose=1                          # 進捗状況を出力\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # テストデータの出力を保存\n",
    "    np.save(os.path.join(result_dir, 'vgg16_test.npy'),\n",
    "            vgg16_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 2000 images belonging to 2 classes.\n",
      "train-label: {'cats': 0, 'dogs': 1}\n",
      "63/63 [==============================] - 175s 3s/step\n",
      "Found 800 images belonging to 2 classes.\n",
      "test-label: {'cats': 0, 'dogs': 1}\n",
      "25/25 [==============================] - 72s 3s/step\n"
     ]
    }
   ],
   "source": [
    "save_VGG16_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4+4+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "def train_FClayer():\n",
    "    '''\n",
    "    VGG16の出力を入力し、FCネットワークで学習する\n",
    "    \n",
    "    '''\n",
    "    # 訓練データのVGG16からの出力を読み込む\n",
    "    train_data = np.load(\n",
    "        os.path.join(result_dir, 'vgg16_train.npy'))    \n",
    "    # VGG16の訓練データの形状を出力\n",
    "    print(train_data.shape)    \n",
    "    # 正解ラベルの作成 最初の2000枚が0(cat),次の2000枚が1(dag)\n",
    "    train_labels = np.array(\n",
    "        [0] * int(num_train / 2) + [1] * int(num_train / 2)\n",
    "    )\n",
    "\n",
    "    # テストデータのVGG16からの出力を読み込む\n",
    "    validation_data = np.load(\n",
    "        os.path.join(result_dir, 'vgg16_test.npy'))\n",
    "    # VGG16のテストデータの形状を出力\n",
    "    print(validation_data.shape)    \n",
    "    # 正解ラベルを作成\n",
    "    # ネコが0、イヌが1\n",
    "    # 最初の800枚(cat)に0、次の800枚(dog)に1を割り当てる\n",
    "    validation_labels = np.array(\n",
    "        [0] * int(num_validation / 2) + [1] * int(num_validation / 2)\n",
    "    )\n",
    "\n",
    "    # FCネットワークの作成\n",
    "    model = Sequential()\n",
    "    # Flatten　全結合層への入力を4階テンソルから2階テンソルに変換する\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    # 全結合層\n",
    "    model.add(Dense(256,                   # ニューロン数は256\n",
    "                    activation='relu'))    # 活性化関数はReLU\n",
    "    model.add(Dropout(0.5))                # ドロップアウト50％\n",
    "    # 出力層\n",
    "    model.add(Dense(1,                     # ニューロン数は256\n",
    "                    activation='sigmoid')) # 活性化関数はReLU\n",
    "\n",
    "    # モデルのコンパイル\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',        # バイナリ用の交差エントロピー誤差\n",
    "        metrics=['accuracy'],              # 学習評価として正解率を指定\n",
    "        # 確率的勾配降下法で最適化 学習率0.0001\n",
    "        # 慣性項(Momentum)を0.9にして前回の更新量に0.9倍して加算することで\n",
    "        # パラメータの更新を慣性的なものにする\n",
    "        optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "    )\n",
    "\n",
    "    # 学習の実行\n",
    "    epoch = 60                             # 学習回数\n",
    "    batch_size = 32                        # ミニバッチのサイズ\n",
    "    history = model.fit(train_data,        # 訓練データ\n",
    "                        train_labels,      # 訓練データの正解ラベル\n",
    "                        epochs=epoch,      # 学習回数\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=1,\n",
    "                        # テストデータと正解ラベル\n",
    "                        validation_data=(validation_data,\n",
    "                                         validation_labels)\n",
    "                        )\n",
    "    \n",
    "    # 学習結果の保存\n",
    "    with open('model.json', 'w') as json_file:\n",
    "        json_file.write(model.to_json())\n",
    "    model.save_weights('weight.h5')\n",
    "\n",
    "    # historyを返す\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 4, 4, 512)\n",
      "(800, 4, 4, 512)\n",
      "Train on 2000 samples, validate on 800 samples\n",
      "Epoch 1/60\n",
      "2000/2000 [==============================] - 1s 469us/step - loss: 0.7462 - accuracy: 0.5335 - val_loss: 0.5965 - val_accuracy: 0.7150\n",
      "Epoch 2/60\n",
      "2000/2000 [==============================] - 1s 408us/step - loss: 0.5920 - accuracy: 0.6775 - val_loss: 0.5281 - val_accuracy: 0.8000\n",
      "Epoch 3/60\n",
      "2000/2000 [==============================] - 1s 403us/step - loss: 0.5339 - accuracy: 0.7355 - val_loss: 0.4904 - val_accuracy: 0.8163\n",
      "Epoch 4/60\n",
      "2000/2000 [==============================] - 1s 408us/step - loss: 0.5005 - accuracy: 0.7590 - val_loss: 0.4628 - val_accuracy: 0.8275\n",
      "Epoch 5/60\n",
      "2000/2000 [==============================] - 1s 406us/step - loss: 0.4726 - accuracy: 0.7880 - val_loss: 0.4400 - val_accuracy: 0.8363\n",
      "Epoch 6/60\n",
      "2000/2000 [==============================] - 1s 400us/step - loss: 0.4530 - accuracy: 0.8025 - val_loss: 0.4212 - val_accuracy: 0.8425\n",
      "Epoch 7/60\n",
      "2000/2000 [==============================] - 1s 448us/step - loss: 0.4336 - accuracy: 0.8070 - val_loss: 0.4067 - val_accuracy: 0.8450\n",
      "Epoch 8/60\n",
      "2000/2000 [==============================] - 1s 411us/step - loss: 0.4178 - accuracy: 0.8190 - val_loss: 0.3925 - val_accuracy: 0.8512\n",
      "Epoch 9/60\n",
      "2000/2000 [==============================] - 1s 415us/step - loss: 0.3930 - accuracy: 0.8355 - val_loss: 0.3848 - val_accuracy: 0.8487\n",
      "Epoch 10/60\n",
      "2000/2000 [==============================] - 1s 416us/step - loss: 0.3950 - accuracy: 0.8275 - val_loss: 0.3703 - val_accuracy: 0.8575\n",
      "Epoch 11/60\n",
      "2000/2000 [==============================] - 1s 405us/step - loss: 0.3788 - accuracy: 0.8350 - val_loss: 0.3624 - val_accuracy: 0.8600\n",
      "Epoch 12/60\n",
      "2000/2000 [==============================] - 1s 411us/step - loss: 0.3568 - accuracy: 0.8560 - val_loss: 0.3556 - val_accuracy: 0.8650\n",
      "Epoch 13/60\n",
      "2000/2000 [==============================] - 1s 413us/step - loss: 0.3735 - accuracy: 0.8435 - val_loss: 0.3476 - val_accuracy: 0.8612\n",
      "Epoch 14/60\n",
      "2000/2000 [==============================] - 1s 419us/step - loss: 0.3530 - accuracy: 0.8545 - val_loss: 0.3450 - val_accuracy: 0.8675\n",
      "Epoch 15/60\n",
      "2000/2000 [==============================] - 1s 413us/step - loss: 0.3558 - accuracy: 0.8515 - val_loss: 0.3369 - val_accuracy: 0.8662\n",
      "Epoch 16/60\n",
      "2000/2000 [==============================] - 1s 402us/step - loss: 0.3363 - accuracy: 0.8570 - val_loss: 0.3338 - val_accuracy: 0.8725\n",
      "Epoch 17/60\n",
      "2000/2000 [==============================] - 1s 418us/step - loss: 0.3433 - accuracy: 0.8535 - val_loss: 0.3287 - val_accuracy: 0.8675\n",
      "Epoch 18/60\n",
      "2000/2000 [==============================] - 1s 407us/step - loss: 0.3262 - accuracy: 0.8635 - val_loss: 0.3287 - val_accuracy: 0.8712\n",
      "Epoch 19/60\n",
      "2000/2000 [==============================] - 1s 418us/step - loss: 0.3301 - accuracy: 0.8710 - val_loss: 0.3211 - val_accuracy: 0.8700\n",
      "Epoch 20/60\n",
      "2000/2000 [==============================] - 1s 417us/step - loss: 0.3250 - accuracy: 0.8700 - val_loss: 0.3148 - val_accuracy: 0.8725\n",
      "Epoch 21/60\n",
      "2000/2000 [==============================] - 1s 409us/step - loss: 0.3091 - accuracy: 0.8795 - val_loss: 0.3095 - val_accuracy: 0.8725\n",
      "Epoch 22/60\n",
      "2000/2000 [==============================] - 1s 416us/step - loss: 0.3077 - accuracy: 0.8730 - val_loss: 0.3074 - val_accuracy: 0.8750\n",
      "Epoch 23/60\n",
      "2000/2000 [==============================] - 1s 400us/step - loss: 0.3125 - accuracy: 0.8650 - val_loss: 0.3053 - val_accuracy: 0.8763\n",
      "Epoch 24/60\n",
      "2000/2000 [==============================] - 1s 408us/step - loss: 0.3127 - accuracy: 0.8725 - val_loss: 0.3022 - val_accuracy: 0.8775\n",
      "Epoch 25/60\n",
      "2000/2000 [==============================] - 1s 408us/step - loss: 0.2980 - accuracy: 0.8805 - val_loss: 0.2997 - val_accuracy: 0.8763\n",
      "Epoch 26/60\n",
      "2000/2000 [==============================] - 1s 451us/step - loss: 0.2976 - accuracy: 0.8845 - val_loss: 0.2959 - val_accuracy: 0.8788\n",
      "Epoch 27/60\n",
      "2000/2000 [==============================] - 1s 416us/step - loss: 0.2941 - accuracy: 0.8790 - val_loss: 0.2942 - val_accuracy: 0.8737\n",
      "Epoch 28/60\n",
      "2000/2000 [==============================] - 1s 421us/step - loss: 0.2891 - accuracy: 0.8775 - val_loss: 0.3079 - val_accuracy: 0.8788\n",
      "Epoch 29/60\n",
      "2000/2000 [==============================] - 1s 425us/step - loss: 0.2826 - accuracy: 0.8870 - val_loss: 0.2908 - val_accuracy: 0.8750\n",
      "Epoch 30/60\n",
      "2000/2000 [==============================] - 1s 408us/step - loss: 0.2867 - accuracy: 0.8885 - val_loss: 0.2896 - val_accuracy: 0.8775\n",
      "Epoch 31/60\n",
      "2000/2000 [==============================] - 1s 419us/step - loss: 0.2761 - accuracy: 0.8940 - val_loss: 0.2880 - val_accuracy: 0.8800\n",
      "Epoch 32/60\n",
      "2000/2000 [==============================] - 1s 426us/step - loss: 0.2765 - accuracy: 0.8955 - val_loss: 0.2852 - val_accuracy: 0.8788\n",
      "Epoch 33/60\n",
      "2000/2000 [==============================] - 1s 412us/step - loss: 0.2683 - accuracy: 0.8950 - val_loss: 0.2847 - val_accuracy: 0.8813\n",
      "Epoch 34/60\n",
      "2000/2000 [==============================] - 1s 425us/step - loss: 0.2764 - accuracy: 0.8845 - val_loss: 0.2816 - val_accuracy: 0.8800\n",
      "Epoch 35/60\n",
      "2000/2000 [==============================] - 1s 419us/step - loss: 0.2555 - accuracy: 0.9085 - val_loss: 0.2874 - val_accuracy: 0.8850\n",
      "Epoch 36/60\n",
      "2000/2000 [==============================] - 1s 416us/step - loss: 0.2583 - accuracy: 0.8985 - val_loss: 0.2790 - val_accuracy: 0.8838\n",
      "Epoch 37/60\n",
      "2000/2000 [==============================] - 1s 414us/step - loss: 0.2590 - accuracy: 0.9015 - val_loss: 0.2816 - val_accuracy: 0.8850\n",
      "Epoch 38/60\n",
      "2000/2000 [==============================] - 1s 417us/step - loss: 0.2570 - accuracy: 0.9010 - val_loss: 0.2785 - val_accuracy: 0.8838\n",
      "Epoch 39/60\n",
      "2000/2000 [==============================] - 1s 427us/step - loss: 0.2566 - accuracy: 0.9035 - val_loss: 0.2735 - val_accuracy: 0.8850\n",
      "Epoch 40/60\n",
      "2000/2000 [==============================] - 1s 415us/step - loss: 0.2541 - accuracy: 0.8980 - val_loss: 0.2742 - val_accuracy: 0.8813\n",
      "Epoch 41/60\n",
      "2000/2000 [==============================] - 1s 438us/step - loss: 0.2547 - accuracy: 0.9010 - val_loss: 0.2739 - val_accuracy: 0.8850\n",
      "Epoch 42/60\n",
      "2000/2000 [==============================] - 1s 417us/step - loss: 0.2585 - accuracy: 0.8970 - val_loss: 0.2710 - val_accuracy: 0.8838\n",
      "Epoch 43/60\n",
      "2000/2000 [==============================] - 1s 427us/step - loss: 0.2441 - accuracy: 0.9065 - val_loss: 0.2685 - val_accuracy: 0.8838\n",
      "Epoch 44/60\n",
      "2000/2000 [==============================] - 1s 415us/step - loss: 0.2459 - accuracy: 0.9055 - val_loss: 0.2670 - val_accuracy: 0.8850\n",
      "Epoch 45/60\n",
      "2000/2000 [==============================] - 1s 431us/step - loss: 0.2453 - accuracy: 0.9080 - val_loss: 0.2673 - val_accuracy: 0.8900\n",
      "Epoch 46/60\n",
      "2000/2000 [==============================] - 1s 419us/step - loss: 0.2418 - accuracy: 0.9090 - val_loss: 0.2710 - val_accuracy: 0.8838\n",
      "Epoch 47/60\n",
      "2000/2000 [==============================] - 1s 426us/step - loss: 0.2419 - accuracy: 0.9085 - val_loss: 0.2639 - val_accuracy: 0.8875\n",
      "Epoch 48/60\n",
      "2000/2000 [==============================] - 1s 417us/step - loss: 0.2392 - accuracy: 0.9060 - val_loss: 0.2682 - val_accuracy: 0.8875\n",
      "Epoch 49/60\n",
      "2000/2000 [==============================] - 1s 424us/step - loss: 0.2364 - accuracy: 0.9080 - val_loss: 0.2706 - val_accuracy: 0.8875\n",
      "Epoch 50/60\n",
      "2000/2000 [==============================] - 1s 425us/step - loss: 0.2398 - accuracy: 0.9030 - val_loss: 0.2643 - val_accuracy: 0.8850\n",
      "Epoch 51/60\n",
      "2000/2000 [==============================] - 1s 425us/step - loss: 0.2344 - accuracy: 0.9075 - val_loss: 0.2652 - val_accuracy: 0.8888\n",
      "Epoch 52/60\n",
      "2000/2000 [==============================] - 1s 413us/step - loss: 0.2392 - accuracy: 0.9040 - val_loss: 0.2592 - val_accuracy: 0.8875\n",
      "Epoch 53/60\n",
      "2000/2000 [==============================] - 1s 418us/step - loss: 0.2337 - accuracy: 0.9065 - val_loss: 0.2644 - val_accuracy: 0.8850\n",
      "Epoch 54/60\n",
      "2000/2000 [==============================] - 1s 425us/step - loss: 0.2349 - accuracy: 0.9035 - val_loss: 0.2670 - val_accuracy: 0.8850\n",
      "Epoch 55/60\n",
      "2000/2000 [==============================] - 1s 428us/step - loss: 0.2291 - accuracy: 0.9125 - val_loss: 0.2744 - val_accuracy: 0.8800\n",
      "Epoch 56/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 403us/step - loss: 0.2244 - accuracy: 0.9150 - val_loss: 0.2593 - val_accuracy: 0.8888\n",
      "Epoch 57/60\n",
      "2000/2000 [==============================] - 1s 422us/step - loss: 0.2248 - accuracy: 0.9140 - val_loss: 0.2571 - val_accuracy: 0.8925\n",
      "Epoch 58/60\n",
      "2000/2000 [==============================] - 1s 411us/step - loss: 0.2247 - accuracy: 0.9140 - val_loss: 0.2649 - val_accuracy: 0.8888\n",
      "Epoch 59/60\n",
      "2000/2000 [==============================] - 1s 416us/step - loss: 0.2227 - accuracy: 0.9180 - val_loss: 0.2541 - val_accuracy: 0.8913\n",
      "Epoch 60/60\n",
      "2000/2000 [==============================] - 1s 425us/step - loss: 0.2106 - accuracy: 0.9165 - val_loss: 0.2608 - val_accuracy: 0.8850\n"
     ]
    }
   ],
   "source": [
    "# VGG16の出力をFCネットワークで学習\n",
    "history = train_FClayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.5964720892906189,\n",
       "  0.528095554113388,\n",
       "  0.4903604483604431,\n",
       "  0.4628378164768219,\n",
       "  0.43996414184570315,\n",
       "  0.4212276566028595,\n",
       "  0.4066667973995209,\n",
       "  0.39250322699546814,\n",
       "  0.3847876960039139,\n",
       "  0.3702836525440216,\n",
       "  0.36238898992538454,\n",
       "  0.3556026792526245,\n",
       "  0.34755451083183286,\n",
       "  0.3449581742286682,\n",
       "  0.3368866240978241,\n",
       "  0.33381281793117523,\n",
       "  0.328712654709816,\n",
       "  0.3287074238061905,\n",
       "  0.32109795093536375,\n",
       "  0.31475110590457916,\n",
       "  0.30954585790634154,\n",
       "  0.30741912364959717,\n",
       "  0.30533028542995455,\n",
       "  0.3021657282114029,\n",
       "  0.2996568512916565,\n",
       "  0.2958667433261871,\n",
       "  0.2942195439338684,\n",
       "  0.30788257777690886,\n",
       "  0.2908347648382187,\n",
       "  0.2896408939361572,\n",
       "  0.28795458018779757,\n",
       "  0.28521288096904757,\n",
       "  0.28470313012599946,\n",
       "  0.2815971124172211,\n",
       "  0.287354941368103,\n",
       "  0.2789727348089218,\n",
       "  0.2816287189722061,\n",
       "  0.27848699271678923,\n",
       "  0.273467658162117,\n",
       "  0.27421831667423247,\n",
       "  0.2738524180650711,\n",
       "  0.27095012962818144,\n",
       "  0.26847497999668124,\n",
       "  0.26703385531902313,\n",
       "  0.26734908401966095,\n",
       "  0.2710383027791977,\n",
       "  0.26390223920345307,\n",
       "  0.26817978084087374,\n",
       "  0.2706248876452446,\n",
       "  0.2642944633960724,\n",
       "  0.2652170318365097,\n",
       "  0.25921944379806516,\n",
       "  0.2643997251987457,\n",
       "  0.2670335841178894,\n",
       "  0.27441568464040755,\n",
       "  0.2593060627579689,\n",
       "  0.2571375325322151,\n",
       "  0.2648742735385895,\n",
       "  0.25408308863639834,\n",
       "  0.26076296210289],\n",
       " 'val_accuracy': [0.7149999737739563,\n",
       "  0.800000011920929,\n",
       "  0.8162500262260437,\n",
       "  0.8274999856948853,\n",
       "  0.8362500071525574,\n",
       "  0.8424999713897705,\n",
       "  0.8450000286102295,\n",
       "  0.8512499928474426,\n",
       "  0.8487499952316284,\n",
       "  0.8575000166893005,\n",
       "  0.8600000143051147,\n",
       "  0.8650000095367432,\n",
       "  0.8612499833106995,\n",
       "  0.8675000071525574,\n",
       "  0.8662499785423279,\n",
       "  0.8725000023841858,\n",
       "  0.8675000071525574,\n",
       "  0.8712499737739563,\n",
       "  0.8700000047683716,\n",
       "  0.8725000023841858,\n",
       "  0.8725000023841858,\n",
       "  0.875,\n",
       "  0.8762500286102295,\n",
       "  0.8774999976158142,\n",
       "  0.8762500286102295,\n",
       "  0.8787500262260437,\n",
       "  0.8737499713897705,\n",
       "  0.8787500262260437,\n",
       "  0.875,\n",
       "  0.8774999976158142,\n",
       "  0.8799999952316284,\n",
       "  0.8787500262260437,\n",
       "  0.8812500238418579,\n",
       "  0.8799999952316284,\n",
       "  0.8849999904632568,\n",
       "  0.8837500214576721,\n",
       "  0.8849999904632568,\n",
       "  0.8837500214576721,\n",
       "  0.8849999904632568,\n",
       "  0.8812500238418579,\n",
       "  0.8849999904632568,\n",
       "  0.8837500214576721,\n",
       "  0.8837500214576721,\n",
       "  0.8849999904632568,\n",
       "  0.8899999856948853,\n",
       "  0.8837500214576721,\n",
       "  0.887499988079071,\n",
       "  0.887499988079071,\n",
       "  0.887499988079071,\n",
       "  0.8849999904632568,\n",
       "  0.8887500166893005,\n",
       "  0.887499988079071,\n",
       "  0.8849999904632568,\n",
       "  0.8849999904632568,\n",
       "  0.8799999952316284,\n",
       "  0.8887500166893005,\n",
       "  0.8924999833106995,\n",
       "  0.8887500166893005,\n",
       "  0.8912500143051147,\n",
       "  0.8849999904632568],\n",
       " 'loss': [0.7461946439743042,\n",
       "  0.5920388891696929,\n",
       "  0.533899554014206,\n",
       "  0.5005356178283692,\n",
       "  0.472624737739563,\n",
       "  0.452964702129364,\n",
       "  0.43358351063728334,\n",
       "  0.41781690311431885,\n",
       "  0.39299095487594604,\n",
       "  0.39504783153533934,\n",
       "  0.3787646589279175,\n",
       "  0.3568002598285675,\n",
       "  0.3735136766433716,\n",
       "  0.352974536895752,\n",
       "  0.35575693225860594,\n",
       "  0.3362949151992798,\n",
       "  0.3433413722515106,\n",
       "  0.32622404289245605,\n",
       "  0.330089205622673,\n",
       "  0.3250311710834503,\n",
       "  0.30908766174316404,\n",
       "  0.3077358503341675,\n",
       "  0.31249387764930725,\n",
       "  0.3127286357879639,\n",
       "  0.29804192304611205,\n",
       "  0.29760410499572754,\n",
       "  0.2941172642707825,\n",
       "  0.28912211322784426,\n",
       "  0.28259165477752685,\n",
       "  0.28671523880958555,\n",
       "  0.27608776760101317,\n",
       "  0.27649989366531375,\n",
       "  0.2682967691421509,\n",
       "  0.27644323205947874,\n",
       "  0.25551404082775114,\n",
       "  0.25825266003608705,\n",
       "  0.25899292922019956,\n",
       "  0.25696363794803617,\n",
       "  0.25657997918128966,\n",
       "  0.2541467001438141,\n",
       "  0.2547184386253357,\n",
       "  0.2584525502920151,\n",
       "  0.24405441749095916,\n",
       "  0.24586540937423706,\n",
       "  0.24528964042663573,\n",
       "  0.24176231265068054,\n",
       "  0.2418870996236801,\n",
       "  0.23920984733104705,\n",
       "  0.23643163204193116,\n",
       "  0.239764146566391,\n",
       "  0.23439400911331176,\n",
       "  0.23918025362491607,\n",
       "  0.2337158440351486,\n",
       "  0.2348915318250656,\n",
       "  0.22910517203807831,\n",
       "  0.2243520005941391,\n",
       "  0.2247817645072937,\n",
       "  0.22471464586257933,\n",
       "  0.22267540156841278,\n",
       "  0.21055681383609773],\n",
       " 'accuracy': [0.5335,\n",
       "  0.6775,\n",
       "  0.7355,\n",
       "  0.759,\n",
       "  0.788,\n",
       "  0.8025,\n",
       "  0.807,\n",
       "  0.819,\n",
       "  0.8355,\n",
       "  0.8275,\n",
       "  0.835,\n",
       "  0.856,\n",
       "  0.8435,\n",
       "  0.8545,\n",
       "  0.8515,\n",
       "  0.857,\n",
       "  0.8535,\n",
       "  0.8635,\n",
       "  0.871,\n",
       "  0.87,\n",
       "  0.8795,\n",
       "  0.873,\n",
       "  0.865,\n",
       "  0.8725,\n",
       "  0.8805,\n",
       "  0.8845,\n",
       "  0.879,\n",
       "  0.8775,\n",
       "  0.887,\n",
       "  0.8885,\n",
       "  0.894,\n",
       "  0.8955,\n",
       "  0.895,\n",
       "  0.8845,\n",
       "  0.9085,\n",
       "  0.8985,\n",
       "  0.9015,\n",
       "  0.901,\n",
       "  0.9035,\n",
       "  0.898,\n",
       "  0.901,\n",
       "  0.897,\n",
       "  0.9065,\n",
       "  0.9055,\n",
       "  0.908,\n",
       "  0.909,\n",
       "  0.9085,\n",
       "  0.906,\n",
       "  0.908,\n",
       "  0.903,\n",
       "  0.9075,\n",
       "  0.904,\n",
       "  0.9065,\n",
       "  0.9035,\n",
       "  0.9125,\n",
       "  0.915,\n",
       "  0.914,\n",
       "  0.914,\n",
       "  0.918,\n",
       "  0.9165]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(history)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d99f873dbfb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# 損失と精度をグラフに出力\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mplot_acc_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-d99f873dbfb0>\u001b[0m in \u001b[0;36mplot_acc_loss\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_acc_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# 精度の推移をプロット\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_acc_loss(history):\n",
    "    # 精度の推移をプロット\n",
    "    plt.plot(history.history['accuracy'],\"-\",label=\"accuracy\")\n",
    "    plt.plot(history.history['val_accuracy'],\"-\",label=\"val_acc\")\n",
    "    plt.title('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # 損失の推移をプロット\n",
    "    plt.plot(history.history['loss'],\"-\",label=\"loss\",)\n",
    "    plt.plot(history.history['val_loss'],\"-\",label=\"val_loss\")\n",
    "    plt.title('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "# 損失と精度をグラフに出力\n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
